{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Data Set, Model and Cross-Validation Setup\n",
    "\n",
    "For compeiting in this task, I focused on training distilled transformers for fast iterating, such as DistillBert and DistilRoBERTa. Also using Bert-base-uncase to validate my results. On this notebook, it only aims to analysis the prediction model produced on validation and test, and post processing.\n",
    "\n",
    "The input sequences available for models are \"question_title\", \"question_body\", \"answer\". The max length for question and answer can be configured differently, here model used 384 for question and 512 for answer since their length difference spotted on data analysis.\n",
    "\n",
    "Model archtitechure are using a shared tranmsformer embedding to ingest \"question_title\" + \"question_body\" for question, \"question_title\" + \"answer\" for answer. Meanwhile, a customized classification head is added on top of that.\n",
    "\n",
    "The training stragegy consists of several part:\n",
    "\n",
    "1) freeze the embedding weight to tune the classification head first,\n",
    "\n",
    "2) unfreeze transformer weights using warm up scheduling to graduately increasing learning rate, and\n",
    "\n",
    "3) use customized early stopping callback while perofmrance on the validation set stop imrpoving.\n",
    "\n",
    "4) also try out some commonly augmentation tricks, such as truncated corpus, drop out words or label soften.\n",
    "\n",
    "\n",
    "Regarding to cross-valation, Based on the well populating on duplicated questions, a good stregegy is to use `GroupKFold` to split data, to well split data further, `category` is also applied to generate group for data split into training and validation set. Meanwhile, the first fold of 5-fold cross-valiation is used to training model and validating the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir: str = \"../input/distilroberta-base_q384_a512\"\n",
    "result_stats_filename: str = \"model_stats.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To dive into prediction\n",
    "\n",
    "To maximize the model performance on eval metrics, to thresholding the predictions from model. This is observed the label distribution in training set and understanding of the quest. The and therefore just  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def spearmanr_ignore_nan(trues: np.array, preds: np.array):\n",
    "    return np.nanmean(\n",
    "        [spearmanr(ta, pa).correlation for ta, pa in\n",
    "         zip(np.transpose(trues), np.transpose(np.nan_to_num(preds)) + 1e-7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open ../input/distilroberta-base_q384_a512/model_stats.hdf5 and found 7:\n",
      "['/test_preds', '/valid_breakdown_metrics', '/valid_group_score', '/valid_overall_metrics', '/valid_preds', '/valid_test_stats_diff', '/valid_trues']\n",
      "read /test_preds: (476, 30)\n",
      "read /valid_breakdown_metrics: (30, 5)\n",
      "read /valid_group_score: (5, 3)\n",
      "read /valid_overall_metrics: (8, 5)\n",
      "read /valid_preds: (1216, 30)\n",
      "read /valid_test_stats_diff: (30, 7)\n",
      "read /valid_trues: (1216, 30)\n"
     ]
    }
   ],
   "source": [
    "# open up the result file from training model\n",
    "file_path = os.path.join(result_dir, result_stats_filename)\n",
    "with pd.HDFStore(file_path, mode='r') as store:\n",
    "    print(f\"open {file_path} and found {len(store.keys())}:\\n{store.keys()}\")\n",
    "    for k, v in store.items():\n",
    "        var_name = k.split('/')[-1]\n",
    "        df = store.get(k)\n",
    "        vars()[var_name] = df\n",
    "        print(f'read {k}: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>test_std</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>ks_stats</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question_type_entity</th>\n",
       "      <td>0.109976</td>\n",
       "      <td>0.144773</td>\n",
       "      <td>-0.034797</td>\n",
       "      <td>0.109976</td>\n",
       "      <td>0.144773</td>\n",
       "      <td>0.073813</td>\n",
       "      <td>0.045241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <td>0.400333</td>\n",
       "      <td>0.432662</td>\n",
       "      <td>-0.032328</td>\n",
       "      <td>0.400333</td>\n",
       "      <td>0.432662</td>\n",
       "      <td>0.093764</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_conversational</th>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.045940</td>\n",
       "      <td>-0.016336</td>\n",
       "      <td>0.029604</td>\n",
       "      <td>0.045940</td>\n",
       "      <td>0.100149</td>\n",
       "      <td>0.001915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_definition</th>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>-0.016298</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>0.072002</td>\n",
       "      <td>0.054286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_well_written</th>\n",
       "      <td>0.790364</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>-0.016243</td>\n",
       "      <td>0.790364</td>\n",
       "      <td>0.806607</td>\n",
       "      <td>0.098505</td>\n",
       "      <td>0.002399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <td>0.511383</td>\n",
       "      <td>0.526840</td>\n",
       "      <td>-0.015457</td>\n",
       "      <td>0.511383</td>\n",
       "      <td>0.526840</td>\n",
       "      <td>0.068733</td>\n",
       "      <td>0.074586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_multi_intent</th>\n",
       "      <td>0.270178</td>\n",
       "      <td>0.284928</td>\n",
       "      <td>-0.014750</td>\n",
       "      <td>0.270178</td>\n",
       "      <td>0.284928</td>\n",
       "      <td>0.046212</td>\n",
       "      <td>0.442014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_body_critical</th>\n",
       "      <td>0.629797</td>\n",
       "      <td>0.644542</td>\n",
       "      <td>-0.014744</td>\n",
       "      <td>0.629797</td>\n",
       "      <td>0.644542</td>\n",
       "      <td>0.078775</td>\n",
       "      <td>0.026821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_compare</th>\n",
       "      <td>0.036706</td>\n",
       "      <td>0.050482</td>\n",
       "      <td>-0.013776</td>\n",
       "      <td>0.036706</td>\n",
       "      <td>0.050482</td>\n",
       "      <td>0.110882</td>\n",
       "      <td>0.000401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_choice</th>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.235489</td>\n",
       "      <td>-0.009056</td>\n",
       "      <td>0.226432</td>\n",
       "      <td>0.235489</td>\n",
       "      <td>0.048354</td>\n",
       "      <td>0.385617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <td>0.911083</td>\n",
       "      <td>0.916856</td>\n",
       "      <td>-0.005773</td>\n",
       "      <td>0.911083</td>\n",
       "      <td>0.916856</td>\n",
       "      <td>0.092741</td>\n",
       "      <td>0.005133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <td>0.593812</td>\n",
       "      <td>0.599166</td>\n",
       "      <td>-0.005354</td>\n",
       "      <td>0.593812</td>\n",
       "      <td>0.599166</td>\n",
       "      <td>0.079037</td>\n",
       "      <td>0.026065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_well_written</th>\n",
       "      <td>0.906067</td>\n",
       "      <td>0.909263</td>\n",
       "      <td>-0.003196</td>\n",
       "      <td>0.906067</td>\n",
       "      <td>0.909263</td>\n",
       "      <td>0.063854</td>\n",
       "      <td>0.116609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_consequence</th>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>0.007034</td>\n",
       "      <td>0.007387</td>\n",
       "      <td>0.062431</td>\n",
       "      <td>0.132015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.074663</td>\n",
       "      <td>0.041463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_spelling</th>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.041727</td>\n",
       "      <td>0.572738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_plausible</th>\n",
       "      <td>0.962257</td>\n",
       "      <td>0.960778</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.962257</td>\n",
       "      <td>0.960778</td>\n",
       "      <td>0.045438</td>\n",
       "      <td>0.463478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_relevance</th>\n",
       "      <td>0.966179</td>\n",
       "      <td>0.964652</td>\n",
       "      <td>0.001527</td>\n",
       "      <td>0.966179</td>\n",
       "      <td>0.964652</td>\n",
       "      <td>0.063336</td>\n",
       "      <td>0.122031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <td>0.681919</td>\n",
       "      <td>0.679936</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>0.681919</td>\n",
       "      <td>0.679936</td>\n",
       "      <td>0.036813</td>\n",
       "      <td>0.725081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <td>0.423696</td>\n",
       "      <td>0.421351</td>\n",
       "      <td>0.002344</td>\n",
       "      <td>0.423696</td>\n",
       "      <td>0.421351</td>\n",
       "      <td>0.035417</td>\n",
       "      <td>0.767086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <td>0.308970</td>\n",
       "      <td>0.306557</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.308970</td>\n",
       "      <td>0.306557</td>\n",
       "      <td>0.046605</td>\n",
       "      <td>0.431316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_helpful</th>\n",
       "      <td>0.926739</td>\n",
       "      <td>0.923685</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.926739</td>\n",
       "      <td>0.923685</td>\n",
       "      <td>0.047386</td>\n",
       "      <td>0.410526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <td>0.852430</td>\n",
       "      <td>0.846362</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.852430</td>\n",
       "      <td>0.846362</td>\n",
       "      <td>0.069286</td>\n",
       "      <td>0.070758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_procedure</th>\n",
       "      <td>0.167984</td>\n",
       "      <td>0.158941</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.167984</td>\n",
       "      <td>0.158941</td>\n",
       "      <td>0.074317</td>\n",
       "      <td>0.042964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <td>0.128945</td>\n",
       "      <td>0.119698</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>0.128945</td>\n",
       "      <td>0.119698</td>\n",
       "      <td>0.082956</td>\n",
       "      <td>0.016818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <td>0.721231</td>\n",
       "      <td>0.710282</td>\n",
       "      <td>0.010949</td>\n",
       "      <td>0.721231</td>\n",
       "      <td>0.710282</td>\n",
       "      <td>0.046986</td>\n",
       "      <td>0.421131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <td>0.798059</td>\n",
       "      <td>0.777605</td>\n",
       "      <td>0.020454</td>\n",
       "      <td>0.798059</td>\n",
       "      <td>0.777605</td>\n",
       "      <td>0.076701</td>\n",
       "      <td>0.033508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <td>0.823592</td>\n",
       "      <td>0.767730</td>\n",
       "      <td>0.055862</td>\n",
       "      <td>0.823592</td>\n",
       "      <td>0.767730</td>\n",
       "      <td>0.124053</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <td>0.508168</td>\n",
       "      <td>0.447640</td>\n",
       "      <td>0.060528</td>\n",
       "      <td>0.508168</td>\n",
       "      <td>0.447640</td>\n",
       "      <td>0.101994</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_instructions</th>\n",
       "      <td>0.540434</td>\n",
       "      <td>0.477535</td>\n",
       "      <td>0.062899</td>\n",
       "      <td>0.540434</td>\n",
       "      <td>0.477535</td>\n",
       "      <td>0.111421</td>\n",
       "      <td>0.000369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       test_mean  valid_mean  mean_diff  test_std  valid_std  ks_stats   p_value\n",
       "question_type_entity                    0.109976    0.144773  -0.034797  0.109976   0.144773  0.073813  0.045241\n",
       "question_opinion_seeking                0.400333    0.432662  -0.032328  0.400333   0.432662  0.093764  0.004500\n",
       "question_conversational                 0.029604    0.045940  -0.016336  0.029604   0.045940  0.100149  0.001915\n",
       "question_type_definition                0.027683    0.043981  -0.016298  0.027683   0.043981  0.072002  0.054286\n",
       "question_well_written                   0.790364    0.806607  -0.016243  0.790364   0.806607  0.098505  0.002399\n",
       "question_interestingness_self           0.511383    0.526840  -0.015457  0.511383   0.526840  0.068733  0.074586\n",
       "question_multi_intent                   0.270178    0.284928  -0.014750  0.270178   0.284928  0.046212  0.442014\n",
       "question_body_critical                  0.629797    0.644542  -0.014744  0.629797   0.644542  0.078775  0.026821\n",
       "question_type_compare                   0.036706    0.050482  -0.013776  0.036706   0.050482  0.110882  0.000401\n",
       "question_type_choice                    0.226432    0.235489  -0.009056  0.226432   0.235489  0.048354  0.385617\n",
       "question_asker_intent_understanding     0.911083    0.916856  -0.005773  0.911083   0.916856  0.092741  0.005133\n",
       "question_interestingness_others         0.593812    0.599166  -0.005354  0.593812   0.599166  0.079037  0.026065\n",
       "answer_well_written                     0.906067    0.909263  -0.003196  0.906067   0.909263  0.063854  0.116609\n",
       "question_type_consequence               0.007034    0.007387  -0.000353  0.007034   0.007387  0.062431  0.132015\n",
       "question_not_really_a_question          0.004549    0.004626  -0.000077  0.004549   0.004626  0.074663  0.041463\n",
       "question_type_spelling                  0.000322    0.000391  -0.000069  0.000322   0.000391  0.041727  0.572738\n",
       "answer_plausible                        0.962257    0.960778   0.001480  0.962257   0.960778  0.045438  0.463478\n",
       "answer_relevance                        0.966179    0.964652   0.001527  0.966179   0.964652  0.063336  0.122031\n",
       "answer_level_of_information             0.681919    0.679936   0.001983  0.681919   0.679936  0.036813  0.725081\n",
       "answer_type_reason_explanation          0.423696    0.421351   0.002344  0.423696   0.421351  0.035417  0.767086\n",
       "question_type_reason_explanation        0.308970    0.306557   0.002413  0.308970   0.306557  0.046605  0.431316\n",
       "answer_helpful                          0.926739    0.923685   0.003054  0.926739   0.923685  0.047386  0.410526\n",
       "answer_satisfaction                     0.852430    0.846362   0.006068  0.852430   0.846362  0.069286  0.070758\n",
       "question_type_procedure                 0.167984    0.158941   0.009043  0.167984   0.158941  0.074317  0.042964\n",
       "answer_type_procedure                   0.128945    0.119698   0.009247  0.128945   0.119698  0.082956  0.016818\n",
       "question_expect_short_answer            0.721231    0.710282   0.010949  0.721231   0.710282  0.046986  0.421131\n",
       "question_fact_seeking                   0.798059    0.777605   0.020454  0.798059   0.777605  0.076701  0.033508\n",
       "question_has_commonly_accepted_answer   0.823592    0.767730   0.055862  0.823592   0.767730  0.124053  0.000047\n",
       "answer_type_instructions                0.508168    0.447640   0.060528  0.508168   0.447640  0.101994  0.001480\n",
       "question_type_instructions              0.540434    0.477535   0.062899  0.540434   0.477535  0.111421  0.000369"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_test_stats_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CULTURE</th>\n",
       "      <td>0.352904</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>0.277749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIFE_ARTS</th>\n",
       "      <td>0.423250</td>\n",
       "      <td>0.018781</td>\n",
       "      <td>0.390112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIENCE</th>\n",
       "      <td>0.412098</td>\n",
       "      <td>0.037894</td>\n",
       "      <td>0.319552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STACKOVERFLOW</th>\n",
       "      <td>0.231550</td>\n",
       "      <td>-0.005066</td>\n",
       "      <td>0.226910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECHNOLOGY</th>\n",
       "      <td>0.354609</td>\n",
       "      <td>0.026638</td>\n",
       "      <td>0.312946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                overall  question    answer\n",
       "CULTURE        0.352904  0.006812  0.277749\n",
       "LIFE_ARTS      0.423250  0.018781  0.390112\n",
       "SCIENCE        0.412098  0.037894  0.319552\n",
       "STACKOVERFLOW  0.231550 -0.005066  0.226910\n",
       "TECHNOLOGY     0.354609  0.026638  0.312946"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_group_score  # this shows our current model performed bad on stackoverflow but great on life_art and science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question_type_spelling</th>\n",
       "      <td>-0.000117</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>2.419421</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.040741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <td>-0.000240</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>2.018759</td>\n",
       "      <td>0.027925</td>\n",
       "      <td>0.048685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_plausible</th>\n",
       "      <td>-0.005185</td>\n",
       "      <td>0.064072</td>\n",
       "      <td>0.067050</td>\n",
       "      <td>0.082279</td>\n",
       "      <td>0.092566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_relevance</th>\n",
       "      <td>0.003366</td>\n",
       "      <td>0.051478</td>\n",
       "      <td>0.053179</td>\n",
       "      <td>0.149110</td>\n",
       "      <td>0.143764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_consequence</th>\n",
       "      <td>0.002892</td>\n",
       "      <td>0.016920</td>\n",
       "      <td>1.645950</td>\n",
       "      <td>0.137412</td>\n",
       "      <td>0.147791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_well_written</th>\n",
       "      <td>-0.001870</td>\n",
       "      <td>0.080743</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>0.170488</td>\n",
       "      <td>0.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_helpful</th>\n",
       "      <td>-0.001719</td>\n",
       "      <td>0.090085</td>\n",
       "      <td>0.097709</td>\n",
       "      <td>0.190092</td>\n",
       "      <td>0.198900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <td>-0.020726</td>\n",
       "      <td>0.279698</td>\n",
       "      <td>0.405620</td>\n",
       "      <td>0.270818</td>\n",
       "      <td>0.267898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <td>-0.003744</td>\n",
       "      <td>0.155941</td>\n",
       "      <td>1.344852</td>\n",
       "      <td>0.255036</td>\n",
       "      <td>0.274146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <td>0.008052</td>\n",
       "      <td>0.098185</td>\n",
       "      <td>0.114915</td>\n",
       "      <td>0.279763</td>\n",
       "      <td>0.280571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_procedure</th>\n",
       "      <td>-0.009818</td>\n",
       "      <td>0.179420</td>\n",
       "      <td>1.203173</td>\n",
       "      <td>0.296217</td>\n",
       "      <td>0.319751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <td>-0.017660</td>\n",
       "      <td>0.103272</td>\n",
       "      <td>0.177594</td>\n",
       "      <td>0.329266</td>\n",
       "      <td>0.339203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <td>-0.009788</td>\n",
       "      <td>0.222289</td>\n",
       "      <td>0.289507</td>\n",
       "      <td>0.461340</td>\n",
       "      <td>0.360641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_compare</th>\n",
       "      <td>-0.005115</td>\n",
       "      <td>0.053916</td>\n",
       "      <td>1.188427</td>\n",
       "      <td>0.690382</td>\n",
       "      <td>0.371635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <td>-0.025057</td>\n",
       "      <td>0.071354</td>\n",
       "      <td>0.108957</td>\n",
       "      <td>0.376104</td>\n",
       "      <td>0.371871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <td>-0.023490</td>\n",
       "      <td>0.090080</td>\n",
       "      <td>0.100832</td>\n",
       "      <td>0.338732</td>\n",
       "      <td>0.379744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_definition</th>\n",
       "      <td>-0.004370</td>\n",
       "      <td>0.044222</td>\n",
       "      <td>1.116426</td>\n",
       "      <td>0.637077</td>\n",
       "      <td>0.383263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <td>0.017222</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.288006</td>\n",
       "      <td>0.505353</td>\n",
       "      <td>0.400180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_conversational</th>\n",
       "      <td>0.023139</td>\n",
       "      <td>0.074823</td>\n",
       "      <td>1.083147</td>\n",
       "      <td>0.546795</td>\n",
       "      <td>0.433244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <td>-0.002152</td>\n",
       "      <td>0.264205</td>\n",
       "      <td>0.613703</td>\n",
       "      <td>0.481496</td>\n",
       "      <td>0.463129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_entity</th>\n",
       "      <td>-0.071993</td>\n",
       "      <td>0.116136</td>\n",
       "      <td>1.595729</td>\n",
       "      <td>0.634762</td>\n",
       "      <td>0.463998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <td>-0.020627</td>\n",
       "      <td>0.129911</td>\n",
       "      <td>0.256632</td>\n",
       "      <td>0.463076</td>\n",
       "      <td>0.467470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_well_written</th>\n",
       "      <td>-0.005301</td>\n",
       "      <td>0.121255</td>\n",
       "      <td>0.151321</td>\n",
       "      <td>0.513345</td>\n",
       "      <td>0.514637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_multi_intent</th>\n",
       "      <td>-0.036436</td>\n",
       "      <td>0.221632</td>\n",
       "      <td>0.891907</td>\n",
       "      <td>0.548396</td>\n",
       "      <td>0.533345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_body_critical</th>\n",
       "      <td>-0.049329</td>\n",
       "      <td>0.147763</td>\n",
       "      <td>0.248253</td>\n",
       "      <td>0.604096</td>\n",
       "      <td>0.592324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <td>0.108054</td>\n",
       "      <td>0.256027</td>\n",
       "      <td>0.617510</td>\n",
       "      <td>0.582079</td>\n",
       "      <td>0.592698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <td>0.091121</td>\n",
       "      <td>0.266918</td>\n",
       "      <td>0.520844</td>\n",
       "      <td>0.637495</td>\n",
       "      <td>0.643880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_choice</th>\n",
       "      <td>0.060838</td>\n",
       "      <td>0.183451</td>\n",
       "      <td>0.619082</td>\n",
       "      <td>0.688738</td>\n",
       "      <td>0.712711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <td>0.020836</td>\n",
       "      <td>0.207127</td>\n",
       "      <td>0.442130</td>\n",
       "      <td>0.770392</td>\n",
       "      <td>0.756496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_instructions</th>\n",
       "      <td>-0.001109</td>\n",
       "      <td>0.197151</td>\n",
       "      <td>0.413813</td>\n",
       "      <td>0.786931</td>\n",
       "      <td>0.757646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           bias       mae      mape   pearson  spearman\n",
       "question_type_spelling                -0.000117  0.000663  2.419421  0.015369  0.040741\n",
       "question_not_really_a_question        -0.000240  0.008854  2.018759  0.027925  0.048685\n",
       "answer_plausible                      -0.005185  0.064072  0.067050  0.082279  0.092566\n",
       "answer_relevance                       0.003366  0.051478  0.053179  0.149110  0.143764\n",
       "question_type_consequence              0.002892  0.016920  1.645950  0.137412  0.147791\n",
       "answer_well_written                   -0.001870  0.080743  0.088983  0.170488  0.164900\n",
       "answer_helpful                        -0.001719  0.090085  0.097709  0.190092  0.198900\n",
       "question_expect_short_answer          -0.020726  0.279698  0.405620  0.270818  0.267898\n",
       "answer_type_procedure                 -0.003744  0.155941  1.344852  0.255036  0.274146\n",
       "answer_satisfaction                    0.008052  0.098185  0.114915  0.279763  0.280571\n",
       "question_type_procedure               -0.009818  0.179420  1.203173  0.296217  0.319751\n",
       "question_interestingness_others       -0.017660  0.103272  0.177594  0.329266  0.339203\n",
       "question_fact_seeking                 -0.009788  0.222289  0.289507  0.461340  0.360641\n",
       "question_type_compare                 -0.005115  0.053916  1.188427  0.690382  0.371635\n",
       "answer_level_of_information           -0.025057  0.071354  0.108957  0.376104  0.371871\n",
       "question_asker_intent_understanding   -0.023490  0.090080  0.100832  0.338732  0.379744\n",
       "question_type_definition              -0.004370  0.044222  1.116426  0.637077  0.383263\n",
       "question_has_commonly_accepted_answer  0.017222  0.226070  0.288006  0.505353  0.400180\n",
       "question_conversational                0.023139  0.074823  1.083147  0.546795  0.433244\n",
       "question_opinion_seeking              -0.002152  0.264205  0.613703  0.481496  0.463129\n",
       "question_type_entity                  -0.071993  0.116136  1.595729  0.634762  0.463998\n",
       "question_interestingness_self         -0.020627  0.129911  0.256632  0.463076  0.467470\n",
       "question_well_written                 -0.005301  0.121255  0.151321  0.513345  0.514637\n",
       "question_multi_intent                 -0.036436  0.221632  0.891907  0.548396  0.533345\n",
       "question_body_critical                -0.049329  0.147763  0.248253  0.604096  0.592324\n",
       "question_type_reason_explanation       0.108054  0.256027  0.617510  0.582079  0.592698\n",
       "answer_type_reason_explanation         0.091121  0.266918  0.520844  0.637495  0.643880\n",
       "question_type_choice                   0.060838  0.183451  0.619082  0.688738  0.712711\n",
       "answer_type_instructions               0.020836  0.207127  0.442130  0.770392  0.756496\n",
       "question_type_instructions            -0.001109  0.197151  0.413813  0.786931  0.757646"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_breakdown_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_asker_intent_understanding  question_body_critical  question_conversational  question_expect_short_answer  question_fact_seeking  question_has_commonly_accepted_answer  question_interestingness_others  question_interestingness_self  question_multi_intent  question_not_really_a_question  question_opinion_seeking  question_type_choice  question_type_compare  question_type_consequence  question_type_definition  question_type_entity  question_type_instructions  question_type_procedure  question_type_reason_explanation  question_type_spelling  question_well_written  answer_helpful  answer_level_of_information  answer_plausible  answer_relevance  answer_satisfaction  answer_type_instructions  answer_type_procedure  answer_type_reason_explanation  answer_well_written\n",
       "qa_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "6                                 1.000000                0.666667                      0.0                      0.500000               1.000000                               1.000000                         0.444444                       0.333333                    0.0                             0.0                  0.500000              0.000000               0.000000                        0.0                  0.000000              0.000000                    1.000000                      0.5                          0.000000                     0.0               0.833333        0.888889                     0.666667          0.888889          1.000000             0.733333                  0.666667               0.666667                        0.000000             0.777778\n",
       "11                                1.000000                0.333333                      0.0                      1.000000               1.000000                               1.000000                         0.666667                       0.555556                    0.0                             0.0                  0.333333              0.333333               0.000000                        0.0                  0.000000              0.000000                    0.666667                      0.0                          0.333333                     0.0               0.888889        0.666667                     0.333333          0.666667          0.666667             0.266667                  0.000000               0.000000                        0.000000             0.888889\n",
       "17                                0.888889                1.000000                      0.0                      0.000000               1.000000                               0.000000                         0.666667                       0.333333                    0.0                             0.0                  0.000000              0.000000               0.333333                        0.0                  0.000000              0.000000                    0.000000                      0.0                          0.666667                     0.0               1.000000        1.000000                     0.666667          1.000000          1.000000             1.000000                  0.000000               0.000000                        1.000000             1.000000\n",
       "24                                0.777778                0.555556                      0.0                      1.000000               0.666667                               1.000000                         0.555556                       0.333333                    0.0                             0.0                  0.333333              1.000000               0.000000                        0.0                  0.000000              0.000000                    0.666667                      0.0                          0.666667                     0.0               0.888889        0.666667                     0.666667          0.666667          0.888889             0.900000                  0.333333               0.333333                        0.666667             1.000000\n",
       "41                                0.888889                0.666667                      0.0                      0.333333               1.000000                               0.666667                         0.555556                       0.444444                    1.0                             0.0                  0.000000              0.333333               0.000000                        0.0                  0.333333              0.333333                    0.000000                      0.0                          0.666667                     0.0               1.000000        0.888889                     0.555556          1.000000          1.000000             0.800000                  0.000000               0.000000                        0.333333             1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_trues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.905412</td>\n",
       "      <td>0.565644</td>\n",
       "      <td>0.010187</td>\n",
       "      <td>0.695093</td>\n",
       "      <td>0.719580</td>\n",
       "      <td>0.796349</td>\n",
       "      <td>0.553067</td>\n",
       "      <td>0.401084</td>\n",
       "      <td>0.075334</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.541578</td>\n",
       "      <td>0.043194</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.001188</td>\n",
       "      <td>0.087725</td>\n",
       "      <td>0.867587</td>\n",
       "      <td>0.278805</td>\n",
       "      <td>0.057896</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.709242</td>\n",
       "      <td>0.894841</td>\n",
       "      <td>0.636292</td>\n",
       "      <td>0.960516</td>\n",
       "      <td>0.958100</td>\n",
       "      <td>0.800894</td>\n",
       "      <td>0.797965</td>\n",
       "      <td>0.112276</td>\n",
       "      <td>0.056069</td>\n",
       "      <td>0.894448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.885103</td>\n",
       "      <td>0.570957</td>\n",
       "      <td>0.009143</td>\n",
       "      <td>0.788105</td>\n",
       "      <td>0.864973</td>\n",
       "      <td>0.894341</td>\n",
       "      <td>0.579482</td>\n",
       "      <td>0.441688</td>\n",
       "      <td>0.310563</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.293361</td>\n",
       "      <td>0.323522</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.008699</td>\n",
       "      <td>0.018006</td>\n",
       "      <td>0.274591</td>\n",
       "      <td>0.302266</td>\n",
       "      <td>0.111757</td>\n",
       "      <td>0.417412</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.736912</td>\n",
       "      <td>0.859903</td>\n",
       "      <td>0.663103</td>\n",
       "      <td>0.934732</td>\n",
       "      <td>0.941381</td>\n",
       "      <td>0.771496</td>\n",
       "      <td>0.212178</td>\n",
       "      <td>0.104292</td>\n",
       "      <td>0.337510</td>\n",
       "      <td>0.865911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.937903</td>\n",
       "      <td>0.777816</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.380662</td>\n",
       "      <td>0.958779</td>\n",
       "      <td>0.900480</td>\n",
       "      <td>0.659576</td>\n",
       "      <td>0.560162</td>\n",
       "      <td>0.708315</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.100381</td>\n",
       "      <td>0.036269</td>\n",
       "      <td>0.428866</td>\n",
       "      <td>0.009380</td>\n",
       "      <td>0.068765</td>\n",
       "      <td>0.059492</td>\n",
       "      <td>0.054747</td>\n",
       "      <td>0.080057</td>\n",
       "      <td>0.785860</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.845310</td>\n",
       "      <td>0.955801</td>\n",
       "      <td>0.733329</td>\n",
       "      <td>0.983123</td>\n",
       "      <td>0.985105</td>\n",
       "      <td>0.921492</td>\n",
       "      <td>0.048606</td>\n",
       "      <td>0.114332</td>\n",
       "      <td>0.877092</td>\n",
       "      <td>0.935182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.892733</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.782923</td>\n",
       "      <td>0.844781</td>\n",
       "      <td>0.853018</td>\n",
       "      <td>0.579164</td>\n",
       "      <td>0.429540</td>\n",
       "      <td>0.438672</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.509196</td>\n",
       "      <td>0.803840</td>\n",
       "      <td>0.055598</td>\n",
       "      <td>0.006097</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>0.437160</td>\n",
       "      <td>0.146408</td>\n",
       "      <td>0.176069</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.756427</td>\n",
       "      <td>0.976458</td>\n",
       "      <td>0.748032</td>\n",
       "      <td>0.988829</td>\n",
       "      <td>0.988576</td>\n",
       "      <td>0.915815</td>\n",
       "      <td>0.383622</td>\n",
       "      <td>0.154989</td>\n",
       "      <td>0.672255</td>\n",
       "      <td>0.944991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.895552</td>\n",
       "      <td>0.612479</td>\n",
       "      <td>0.071921</td>\n",
       "      <td>0.455128</td>\n",
       "      <td>0.862793</td>\n",
       "      <td>0.679102</td>\n",
       "      <td>0.644888</td>\n",
       "      <td>0.591892</td>\n",
       "      <td>0.793374</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.342298</td>\n",
       "      <td>0.299315</td>\n",
       "      <td>0.425462</td>\n",
       "      <td>0.027337</td>\n",
       "      <td>0.137157</td>\n",
       "      <td>0.048637</td>\n",
       "      <td>0.106113</td>\n",
       "      <td>0.117016</td>\n",
       "      <td>0.480605</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.812502</td>\n",
       "      <td>0.883858</td>\n",
       "      <td>0.644396</td>\n",
       "      <td>0.948813</td>\n",
       "      <td>0.941258</td>\n",
       "      <td>0.819342</td>\n",
       "      <td>0.073691</td>\n",
       "      <td>0.092941</td>\n",
       "      <td>0.702519</td>\n",
       "      <td>0.876863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_asker_intent_understanding  question_body_critical  question_conversational  question_expect_short_answer  question_fact_seeking  question_has_commonly_accepted_answer  question_interestingness_others  question_interestingness_self  question_multi_intent  question_not_really_a_question  question_opinion_seeking  question_type_choice  question_type_compare  question_type_consequence  question_type_definition  question_type_entity  question_type_instructions  question_type_procedure  question_type_reason_explanation  question_type_spelling  question_well_written  answer_helpful  answer_level_of_information  answer_plausible  answer_relevance  answer_satisfaction  answer_type_instructions  answer_type_procedure  answer_type_reason_explanation  answer_well_written\n",
       "qa_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "6                                 0.905412                0.565644                 0.010187                      0.695093               0.719580                               0.796349                         0.553067                       0.401084               0.075334                        0.005072                  0.541578              0.043194               0.005633                   0.000470                  0.001188              0.087725                    0.867587                 0.278805                          0.057896                0.000018               0.709242        0.894841                     0.636292          0.960516          0.958100             0.800894                  0.797965               0.112276                        0.056069             0.894448\n",
       "11                                0.885103                0.570957                 0.009143                      0.788105               0.864973                               0.894341                         0.579482                       0.441688               0.310563                        0.003818                  0.293361              0.323522               0.013668                   0.008699                  0.018006              0.274591                    0.302266                 0.111757                          0.417412                0.001279               0.736912        0.859903                     0.663103          0.934732          0.941381             0.771496                  0.212178               0.104292                        0.337510             0.865911\n",
       "17                                0.937903                0.777816                 0.008757                      0.380662               0.958779                               0.900480                         0.659576                       0.560162               0.708315                        0.000239                  0.100381              0.036269               0.428866                   0.009380                  0.068765              0.059492                    0.054747                 0.080057                          0.785860                0.000068               0.845310        0.955801                     0.733329          0.983123          0.985105             0.921492                  0.048606               0.114332                        0.877092             0.935182\n",
       "24                                0.892733                0.493150                 0.007811                      0.782923               0.844781                               0.853018                         0.579164                       0.429540               0.438672                        0.000694                  0.509196              0.803840               0.055598                   0.006097                  0.001714              0.076900                    0.437160                 0.146408                          0.176069                0.000050               0.756427        0.976458                     0.748032          0.988829          0.988576             0.915815                  0.383622               0.154989                        0.672255             0.944991\n",
       "41                                0.895552                0.612479                 0.071921                      0.455128               0.862793                               0.679102                         0.644888                       0.591892               0.793374                        0.002446                  0.342298              0.299315               0.425462                   0.027337                  0.137157              0.048637                    0.106113                 0.117016                          0.480605                0.001811               0.812502        0.883858                     0.644396          0.948813          0.941258             0.819342                  0.073691               0.092941                        0.702519             0.876863"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../nlp_utils\")\n",
    "\n",
    "from nlp_utils import OptimalRounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting: question_asker_intent_understanding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting: question_body_critical\n",
      "fitting: question_conversational\n",
      "fitting: question_expect_short_answer\n",
      "fitting: question_fact_seeking\n",
      "fitting: question_has_commonly_accepted_answer\n",
      "fitting: question_interestingness_others\n",
      "fitting: question_interestingness_self\n",
      "fitting: question_multi_intent\n",
      "fitting: question_not_really_a_question\n",
      "fitting: question_opinion_seeking\n",
      "fitting: question_type_choice\n",
      "fitting: question_type_compare\n",
      "fitting: question_type_consequence\n",
      "fitting: question_type_definition\n",
      "fitting: question_type_entity\n",
      "fitting: question_type_instructions\n",
      "fitting: question_type_procedure\n",
      "fitting: question_type_reason_explanation\n",
      "fitting: question_type_spelling\n",
      "fitting: question_well_written\n",
      "fitting: answer_helpful\n",
      "fitting: answer_level_of_information\n",
      "fitting: answer_plausible\n",
      "fitting: answer_relevance\n",
      "fitting: answer_satisfaction\n",
      "fitting: answer_type_instructions\n",
      "fitting: answer_type_procedure\n",
      "fitting: answer_type_reason_explanation\n",
      "fitting: answer_well_written\n"
     ]
    }
   ],
   "source": [
    "# training optimal rounder from the training distribution\n",
    "\n",
    "df = pd.read_csv('../input/google-quest-challenge/train.csv')[valid_preds.columns]\n",
    "opt = OptimalRounder(ref=df)\n",
    "valid_preds_opt = opt.fit_transform(valid_trues, valid_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_asker_intent_understanding      0.379744\n",
       "question_body_critical                   0.592324\n",
       "question_conversational                  0.433244\n",
       "question_expect_short_answer             0.267898\n",
       "question_fact_seeking                    0.360641\n",
       "question_has_commonly_accepted_answer    0.400180\n",
       "question_interestingness_others          0.339203\n",
       "question_interestingness_self            0.467470\n",
       "question_multi_intent                    0.533345\n",
       "question_not_really_a_question           0.048685\n",
       "question_opinion_seeking                 0.463129\n",
       "question_type_choice                     0.712711\n",
       "question_type_compare                    0.371635\n",
       "question_type_consequence                0.147791\n",
       "question_type_definition                 0.383263\n",
       "question_type_entity                     0.463998\n",
       "question_type_instructions               0.757646\n",
       "question_type_procedure                  0.319751\n",
       "question_type_reason_explanation         0.592698\n",
       "question_type_spelling                   0.040741\n",
       "question_well_written                    0.514637\n",
       "answer_helpful                           0.198900\n",
       "answer_level_of_information              0.371871\n",
       "answer_plausible                         0.092566\n",
       "answer_relevance                         0.143764\n",
       "answer_satisfaction                      0.280571\n",
       "answer_type_instructions                 0.756496\n",
       "answer_type_procedure                    0.274146\n",
       "answer_type_reason_explanation           0.643880\n",
       "answer_well_written                      0.164900\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores_orig = valid_trues.apply(lambda x: x.corr(valid_preds[x.name], method='spearman'))\n",
    "valid_scores_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_asker_intent_understanding      0.372308\n",
       "question_body_critical                   0.590384\n",
       "question_conversational                  0.519570\n",
       "question_expect_short_answer             0.286429\n",
       "question_fact_seeking                    0.373448\n",
       "question_has_commonly_accepted_answer    0.446220\n",
       "question_interestingness_others          0.342085\n",
       "question_interestingness_self            0.477320\n",
       "question_multi_intent                    0.540809\n",
       "question_not_really_a_question                NaN\n",
       "question_opinion_seeking                 0.466753\n",
       "question_type_choice                     0.719488\n",
       "question_type_compare                    0.604133\n",
       "question_type_consequence                     NaN\n",
       "question_type_definition                 0.597205\n",
       "question_type_entity                     0.599168\n",
       "question_type_instructions               0.779938\n",
       "question_type_procedure                  0.341829\n",
       "question_type_reason_explanation         0.593394\n",
       "question_type_spelling                        NaN\n",
       "question_well_written                    0.511276\n",
       "answer_helpful                           0.200110\n",
       "answer_level_of_information              0.377286\n",
       "answer_plausible                         0.107161\n",
       "answer_relevance                         0.168359\n",
       "answer_satisfaction                      0.295415\n",
       "answer_type_instructions                 0.764063\n",
       "answer_type_procedure                    0.287922\n",
       "answer_type_reason_explanation           0.643748\n",
       "answer_well_written                      0.168455\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score after post processing on validation set\n",
    "valid_scores_opt = valid_trues.apply(lambda x: x.corr(valid_preds_opt[x.name], method='spearman'))\n",
    "valid_scores_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_asker_intent_understanding      5\n",
       "question_body_critical                   7\n",
       "question_conversational                  5\n",
       "question_expect_short_answer             5\n",
       "question_fact_seeking                    5\n",
       "question_has_commonly_accepted_answer    5\n",
       "question_interestingness_others          5\n",
       "question_interestingness_self            5\n",
       "question_multi_intent                    5\n",
       "question_not_really_a_question           1\n",
       "question_opinion_seeking                 5\n",
       "question_type_choice                     5\n",
       "question_type_compare                    5\n",
       "question_type_consequence                1\n",
       "question_type_definition                 4\n",
       "question_type_entity                     5\n",
       "question_type_instructions               5\n",
       "question_type_procedure                  4\n",
       "question_type_reason_explanation         5\n",
       "question_type_spelling                   1\n",
       "question_well_written                    8\n",
       "answer_helpful                           5\n",
       "answer_level_of_information              5\n",
       "answer_plausible                         3\n",
       "answer_relevance                         4\n",
       "answer_satisfaction                      7\n",
       "answer_type_instructions                 5\n",
       "answer_type_procedure                    5\n",
       "answer_type_reason_explanation           5\n",
       "answer_well_written                      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds_opt.apply(lambda x: x.nunique())  \n",
    "# check the unique value counts in every index after post processing, only one unique value make scoring become NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_type_compare                    0.232498\n",
       "question_type_definition                 0.213943\n",
       "question_type_entity                     0.135171\n",
       "question_conversational                  0.086326\n",
       "question_has_commonly_accepted_answer    0.046041\n",
       "answer_relevance                         0.024595\n",
       "question_type_instructions               0.022292\n",
       "question_type_procedure                  0.022078\n",
       "question_expect_short_answer             0.018531\n",
       "answer_satisfaction                      0.014844\n",
       "answer_plausible                         0.014596\n",
       "answer_type_procedure                    0.013776\n",
       "question_fact_seeking                    0.012807\n",
       "question_interestingness_self            0.009850\n",
       "answer_type_instructions                 0.007566\n",
       "question_multi_intent                    0.007464\n",
       "question_type_choice                     0.006776\n",
       "answer_level_of_information              0.005415\n",
       "question_opinion_seeking                 0.003624\n",
       "answer_well_written                      0.003555\n",
       "question_interestingness_others          0.002882\n",
       "answer_helpful                           0.001211\n",
       "question_type_reason_explanation         0.000696\n",
       "answer_type_reason_explanation          -0.000133\n",
       "question_body_critical                  -0.001940\n",
       "question_well_written                   -0.003361\n",
       "question_asker_intent_understanding     -0.007436\n",
       "question_not_really_a_question                NaN\n",
       "question_type_consequence                     NaN\n",
       "question_type_spelling                        NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eyeballing the improvement on every attribute\n",
    "valid_scores_opt_diff = (valid_scores_opt - valid_scores_orig).sort_values(ascending=False)\n",
    "valid_scores_opt_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select 24 labels getting improve: ['question_type_compare', 'question_type_definition', 'question_type_entity', 'question_conversational', 'question_has_commonly_accepted_answer', 'answer_relevance', 'question_type_instructions', 'question_type_procedure', 'question_expect_short_answer', 'answer_satisfaction', 'answer_plausible', 'answer_type_procedure', 'question_fact_seeking', 'question_interestingness_self', 'answer_type_instructions', 'question_multi_intent', 'question_type_choice', 'answer_level_of_information', 'question_opinion_seeking', 'answer_well_written', 'question_interestingness_others', 'answer_helpful', 'question_type_reason_explanation', 'answer_type_reason_explanation']\n"
     ]
    }
   ],
   "source": [
    "# apply useful columns only, has improvement, and not NaN in metrics\n",
    "use_cols = valid_scores_opt_diff.loc[valid_scores_opt_diff > -.0010].dropna().index.tolist()\n",
    "print(f\"select {len(use_cols)} labels getting improve: {use_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig score=0.384, optimized score=0.414, improve=0.030\n"
     ]
    }
   ],
   "source": [
    "# calculate the lift from post processing\n",
    "valid_preds_opt_final = valid_preds.copy()\n",
    "valid_preds_opt_final[use_cols] = opt.transform(valid_preds[use_cols])\n",
    "\n",
    "score_orig = spearmanr_ignore_nan(valid_trues.values, valid_preds.values)\n",
    "score_opt = spearmanr_ignore_nan(valid_trues.values, valid_preds_opt_final.values)\n",
    "\n",
    "print(f\"orig score={score_orig:.3f}, optimized score={score_opt:.3f}, improve={score_opt-score_orig:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>qa_id</th>\n",
       "      <th>39</th>\n",
       "      <th>46</th>\n",
       "      <th>70</th>\n",
       "      <th>132</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <td>0.947565</td>\n",
       "      <td>0.867423</td>\n",
       "      <td>0.945147</td>\n",
       "      <td>0.879081</td>\n",
       "      <td>0.907718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_body_critical</th>\n",
       "      <td>0.669461</td>\n",
       "      <td>0.515113</td>\n",
       "      <td>0.765663</td>\n",
       "      <td>0.377438</td>\n",
       "      <td>0.535705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_conversational</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_multi_intent</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.009642</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_choice</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_compare</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_consequence</th>\n",
       "      <td>0.096150</td>\n",
       "      <td>0.000984</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.014083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_definition</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_entity</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_instructions</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_procedure</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_spelling</th>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.001427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_well_written</th>\n",
       "      <td>0.931368</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>0.876816</td>\n",
       "      <td>0.653403</td>\n",
       "      <td>0.694662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_helpful</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_plausible</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_relevance</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_well_written</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "qa_id                                       39        46        70        132       200\n",
       "question_asker_intent_understanding    0.947565  0.867423  0.945147  0.879081  0.907718\n",
       "question_body_critical                 0.669461  0.515113  0.765663  0.377438  0.535705\n",
       "question_conversational                1.000000  0.000000  0.000000  0.000000  0.000000\n",
       "question_expect_short_answer           0.333333  0.500000  0.500000  0.500000  0.500000\n",
       "question_fact_seeking                  0.000000  0.666667  0.666667  0.500000  0.666667\n",
       "question_has_commonly_accepted_answer  0.333333  1.000000  1.000000  1.000000  1.000000\n",
       "question_interestingness_others        0.888889  0.666667  0.833333  0.666667  0.777778\n",
       "question_interestingness_self          0.888889  0.666667  0.777778  0.666667  0.777778\n",
       "question_multi_intent                  1.000000  0.000000  0.000000  0.000000  0.666667\n",
       "question_not_really_a_question         0.001565  0.005538  0.001050  0.009642  0.005300\n",
       "question_opinion_seeking               1.000000  0.500000  0.333333  0.666667  0.333333\n",
       "question_type_choice                   0.666667  0.500000  1.000000  0.000000  1.000000\n",
       "question_type_compare                  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "question_type_consequence              0.096150  0.000984  0.036702  0.001957  0.014083\n",
       "question_type_definition               0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "question_type_entity                   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "question_type_instructions             0.000000  1.000000  0.333333  1.000000  0.500000\n",
       "question_type_procedure                0.333333  0.500000  0.000000  0.500000  0.500000\n",
       "question_type_reason_explanation       0.666667  0.000000  0.666667  0.666667  0.500000\n",
       "question_type_spelling                 0.000068  0.000018  0.000211  0.000035  0.001427\n",
       "question_well_written                  0.931368  0.585043  0.876816  0.653403  0.694662\n",
       "answer_helpful                         0.777778  0.833333  0.833333  0.888889  0.833333\n",
       "answer_level_of_information            0.777778  0.777778  0.777778  0.833333  0.777778\n",
       "answer_plausible                       1.000000  1.000000  1.000000  1.000000  1.000000\n",
       "answer_relevance                       0.777778  1.000000  0.888889  1.000000  0.888889\n",
       "answer_satisfaction                    0.700000  0.900000  0.866667  0.900000  0.900000\n",
       "answer_type_instructions               0.000000  1.000000  0.000000  1.000000  0.500000\n",
       "answer_type_procedure                  0.333333  0.500000  0.333333  0.500000  0.500000\n",
       "answer_type_reason_explanation         0.666667  0.000000  0.666667  0.666667  0.666667\n",
       "answer_well_written                    0.888889  0.833333  0.888889  0.888889  0.888889"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# successfully apply the same post processing to test prediction\n",
    "test_preds[use_cols] = opt.transform(test_preds[use_cols])\n",
    "test_preds.head().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
