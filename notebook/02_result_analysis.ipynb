{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Data Set, Model and Cross-Validation Setup\n",
    "\n",
    "For compeiting in this task, I focused on training distilled transformers for fast iterating, such as DistillBert and DistilRoBERTa. Also using Bert-base-uncase to validate my results. On this notebook, it focused on analysis the produced prediction on validation and test, and then performing post processing.\n",
    "\n",
    "The input sequences available for models are \"question_title\", \"question_body\", \"answer\". The max length for question and answer can be configured differently, here model used 384 for question and 512 for answer since their length difference spotted on data analysis. The key parameters are stored in configs and easily to be reviewed.\n",
    "\n",
    "The model archtitechure are using a shared weights of tranmsformer embedding to ingest \"question_title\" + \"question_body\" for question, \"question_title\" + \"answer\" for answer, respectively. Meanwhile, a customized classification head is added on top of that.\n",
    "\n",
    "The training stragegy consists of several part:\n",
    "\n",
    "1) freeze the pretrainined weights of embedding/transformer to tune the classification head first,\n",
    "\n",
    "2) unfreeze transformer weights using warm up scheduling to graduately increasing learning rate, and\n",
    "\n",
    "3) use customized early stopping callback while perofmrance on the validation set stop imrpoving.\n",
    "\n",
    "4) also try out some commonly augmentation tricks, such as truncated corpus, drop out words or label soften.\n",
    "\n",
    "\n",
    "Regarding to cross-valation, Based on the well populating on duplicated questions, a good stregegy is to use `GroupKFold` to split data, to well split data further, `category` is also applied to generate group for data split into training and validation set. Meanwhile, the first fold of 5-fold cross-valiation is used to training model and validating the model's performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import essential modules\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir: str = \"../input/distilroberta-base_q384_a512\"\n",
    "result_stats_filename: str = \"model_stats.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To dive into prediction\n",
    "\n",
    "To maximize the model performance on eval metrics, to thresholding the predictions from model. This is observed the label distribution in training set and understanding of the quest. The and therefore just  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "def spearmanr_ignore_nan(trues: np.array, preds: np.array):\n",
    "    return np.nanmean(\n",
    "        [spearmanr(ta, pa).correlation for ta, pa in\n",
    "         zip(np.transpose(trues), np.transpose(np.nan_to_num(preds)) + 1e-7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "open ../input/distilroberta-base_q384_a512/model_stats.hdf5 and found 7:\n",
      "['/test_preds', '/valid_breakdown_metrics', '/valid_group_score', '/valid_overall_metrics', '/valid_preds', '/valid_test_stats_diff', '/valid_trues']\n",
      "read /test_preds: (476, 30)\n",
      "read /valid_breakdown_metrics: (30, 5)\n",
      "read /valid_group_score: (5, 1)\n",
      "read /valid_overall_metrics: (8, 5)\n",
      "read /valid_preds: (1216, 30)\n",
      "read /valid_test_stats_diff: (30, 7)\n",
      "read /valid_trues: (1216, 30)\n"
     ]
    }
   ],
   "source": [
    "# open up the result file from training model\n",
    "file_path = os.path.join(result_dir, result_stats_filename)\n",
    "with pd.HDFStore(file_path, mode='r') as store:\n",
    "    print(f\"open {file_path} and found {len(store.keys())}:\\n{store.keys()}\")\n",
    "    for k, v in store.items():\n",
    "        var_name = k.split('/')[-1]\n",
    "        df = store.get(k)\n",
    "        vars()[var_name] = df\n",
    "        print(f'read {k}: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_mean</th>\n",
       "      <th>valid_mean</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>test_std</th>\n",
       "      <th>valid_std</th>\n",
       "      <th>ks_stats</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <td>0.416924</td>\n",
       "      <td>0.448605</td>\n",
       "      <td>-0.031682</td>\n",
       "      <td>0.416924</td>\n",
       "      <td>0.448605</td>\n",
       "      <td>0.091414</td>\n",
       "      <td>0.006076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_entity</th>\n",
       "      <td>0.091590</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>-0.026416</td>\n",
       "      <td>0.091590</td>\n",
       "      <td>0.118006</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.197096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_body_critical</th>\n",
       "      <td>0.610354</td>\n",
       "      <td>0.627512</td>\n",
       "      <td>-0.017158</td>\n",
       "      <td>0.610354</td>\n",
       "      <td>0.627512</td>\n",
       "      <td>0.089210</td>\n",
       "      <td>0.007998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_definition</th>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>-0.016682</td>\n",
       "      <td>0.022786</td>\n",
       "      <td>0.039467</td>\n",
       "      <td>0.100336</td>\n",
       "      <td>0.001866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_conversational</th>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.043803</td>\n",
       "      <td>-0.015718</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.043803</td>\n",
       "      <td>0.103100</td>\n",
       "      <td>0.001265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_well_written</th>\n",
       "      <td>0.808299</td>\n",
       "      <td>0.822846</td>\n",
       "      <td>-0.014548</td>\n",
       "      <td>0.808299</td>\n",
       "      <td>0.822846</td>\n",
       "      <td>0.100218</td>\n",
       "      <td>0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <td>0.498091</td>\n",
       "      <td>0.512260</td>\n",
       "      <td>-0.014169</td>\n",
       "      <td>0.498091</td>\n",
       "      <td>0.512260</td>\n",
       "      <td>0.076149</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_compare</th>\n",
       "      <td>0.031084</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>-0.013034</td>\n",
       "      <td>0.031084</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.114047</td>\n",
       "      <td>0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_multi_intent</th>\n",
       "      <td>0.233776</td>\n",
       "      <td>0.244053</td>\n",
       "      <td>-0.010277</td>\n",
       "      <td>0.233776</td>\n",
       "      <td>0.244053</td>\n",
       "      <td>0.037000</td>\n",
       "      <td>0.719376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_choice</th>\n",
       "      <td>0.253075</td>\n",
       "      <td>0.260613</td>\n",
       "      <td>-0.007538</td>\n",
       "      <td>0.253075</td>\n",
       "      <td>0.260613</td>\n",
       "      <td>0.040669</td>\n",
       "      <td>0.605361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <td>0.581834</td>\n",
       "      <td>0.588981</td>\n",
       "      <td>-0.007147</td>\n",
       "      <td>0.581834</td>\n",
       "      <td>0.588981</td>\n",
       "      <td>0.072306</td>\n",
       "      <td>0.052666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <td>0.908389</td>\n",
       "      <td>0.914345</td>\n",
       "      <td>-0.005956</td>\n",
       "      <td>0.908389</td>\n",
       "      <td>0.914345</td>\n",
       "      <td>0.091179</td>\n",
       "      <td>0.006259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_well_written</th>\n",
       "      <td>0.917593</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>-0.002265</td>\n",
       "      <td>0.917593</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>0.061436</td>\n",
       "      <td>0.143749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_consequence</th>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.006952</td>\n",
       "      <td>-0.000389</td>\n",
       "      <td>0.006564</td>\n",
       "      <td>0.006952</td>\n",
       "      <td>0.073681</td>\n",
       "      <td>0.045849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_spelling</th>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.037311</td>\n",
       "      <td>0.709850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.076985</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <td>0.432919</td>\n",
       "      <td>0.431345</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.432919</td>\n",
       "      <td>0.431345</td>\n",
       "      <td>0.041208</td>\n",
       "      <td>0.588686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_plausible</th>\n",
       "      <td>0.962735</td>\n",
       "      <td>0.961130</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.962735</td>\n",
       "      <td>0.961130</td>\n",
       "      <td>0.047117</td>\n",
       "      <td>0.417632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_relevance</th>\n",
       "      <td>0.967326</td>\n",
       "      <td>0.965690</td>\n",
       "      <td>0.001635</td>\n",
       "      <td>0.967326</td>\n",
       "      <td>0.965690</td>\n",
       "      <td>0.058305</td>\n",
       "      <td>0.186190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <td>0.676108</td>\n",
       "      <td>0.673113</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>0.676108</td>\n",
       "      <td>0.673113</td>\n",
       "      <td>0.053012</td>\n",
       "      <td>0.279359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_helpful</th>\n",
       "      <td>0.930383</td>\n",
       "      <td>0.927332</td>\n",
       "      <td>0.003050</td>\n",
       "      <td>0.930383</td>\n",
       "      <td>0.927332</td>\n",
       "      <td>0.080488</td>\n",
       "      <td>0.022215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <td>0.276249</td>\n",
       "      <td>0.271518</td>\n",
       "      <td>0.004732</td>\n",
       "      <td>0.276249</td>\n",
       "      <td>0.271518</td>\n",
       "      <td>0.045880</td>\n",
       "      <td>0.451150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <td>0.852663</td>\n",
       "      <td>0.845496</td>\n",
       "      <td>0.007166</td>\n",
       "      <td>0.852663</td>\n",
       "      <td>0.845496</td>\n",
       "      <td>0.082423</td>\n",
       "      <td>0.017871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_procedure</th>\n",
       "      <td>0.166180</td>\n",
       "      <td>0.156733</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.166180</td>\n",
       "      <td>0.156733</td>\n",
       "      <td>0.080032</td>\n",
       "      <td>0.023367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <td>0.144132</td>\n",
       "      <td>0.133230</td>\n",
       "      <td>0.010902</td>\n",
       "      <td>0.144132</td>\n",
       "      <td>0.133230</td>\n",
       "      <td>0.097724</td>\n",
       "      <td>0.002666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <td>0.703461</td>\n",
       "      <td>0.692459</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.703461</td>\n",
       "      <td>0.692459</td>\n",
       "      <td>0.038672</td>\n",
       "      <td>0.667602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <td>0.804253</td>\n",
       "      <td>0.783605</td>\n",
       "      <td>0.020648</td>\n",
       "      <td>0.804253</td>\n",
       "      <td>0.783605</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <td>0.798511</td>\n",
       "      <td>0.741867</td>\n",
       "      <td>0.056644</td>\n",
       "      <td>0.798511</td>\n",
       "      <td>0.741867</td>\n",
       "      <td>0.120660</td>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <td>0.521494</td>\n",
       "      <td>0.458585</td>\n",
       "      <td>0.062909</td>\n",
       "      <td>0.521494</td>\n",
       "      <td>0.458585</td>\n",
       "      <td>0.109700</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_instructions</th>\n",
       "      <td>0.560661</td>\n",
       "      <td>0.497071</td>\n",
       "      <td>0.063591</td>\n",
       "      <td>0.560661</td>\n",
       "      <td>0.497071</td>\n",
       "      <td>0.111697</td>\n",
       "      <td>0.000354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       test_mean  valid_mean  mean_diff  test_std  valid_std  ks_stats   p_value\n",
       "question_opinion_seeking                0.416924    0.448605  -0.031682  0.416924   0.448605  0.091414  0.006076\n",
       "question_type_entity                    0.091590    0.118006  -0.026416  0.091590   0.118006  0.057593  0.197096\n",
       "question_body_critical                  0.610354    0.627512  -0.017158  0.610354   0.627512  0.089210  0.007998\n",
       "question_type_definition                0.022786    0.039467  -0.016682  0.022786   0.039467  0.100336  0.001866\n",
       "question_conversational                 0.028085    0.043803  -0.015718  0.028085   0.043803  0.103100  0.001265\n",
       "question_well_written                   0.808299    0.822846  -0.014548  0.808299   0.822846  0.100218  0.001896\n",
       "question_interestingness_self           0.498091    0.512260  -0.014169  0.498091   0.512260  0.076149  0.035521\n",
       "question_type_compare                   0.031084    0.044118  -0.013034  0.031084   0.044118  0.114047  0.000245\n",
       "question_multi_intent                   0.233776    0.244053  -0.010277  0.233776   0.244053  0.037000  0.719376\n",
       "question_type_choice                    0.253075    0.260613  -0.007538  0.253075   0.260613  0.040669  0.605361\n",
       "question_interestingness_others         0.581834    0.588981  -0.007147  0.581834   0.588981  0.072306  0.052666\n",
       "question_asker_intent_understanding     0.908389    0.914345  -0.005956  0.908389   0.914345  0.091179  0.006259\n",
       "answer_well_written                     0.917593    0.919858  -0.002265  0.917593   0.919858  0.061436  0.143749\n",
       "question_type_consequence               0.006564    0.006952  -0.000389  0.006564   0.006952  0.073681  0.045849\n",
       "question_type_spelling                  0.000310    0.000351  -0.000041  0.000310   0.000351  0.037311  0.709850\n",
       "question_not_really_a_question          0.004260    0.004141   0.000119  0.004260   0.004141  0.076985  0.032516\n",
       "answer_type_reason_explanation          0.432919    0.431345   0.001574  0.432919   0.431345  0.041208  0.588686\n",
       "answer_plausible                        0.962735    0.961130   0.001605  0.962735   0.961130  0.047117  0.417632\n",
       "answer_relevance                        0.967326    0.965690   0.001635  0.967326   0.965690  0.058305  0.186190\n",
       "answer_level_of_information             0.676108    0.673113   0.002995  0.676108   0.673113  0.053012  0.279359\n",
       "answer_helpful                          0.930383    0.927332   0.003050  0.930383   0.927332  0.080488  0.022215\n",
       "question_type_reason_explanation        0.276249    0.271518   0.004732  0.276249   0.271518  0.045880  0.451150\n",
       "answer_satisfaction                     0.852663    0.845496   0.007166  0.852663   0.845496  0.082423  0.017871\n",
       "question_type_procedure                 0.166180    0.156733   0.009447  0.166180   0.156733  0.080032  0.023367\n",
       "answer_type_procedure                   0.144132    0.133230   0.010902  0.144132   0.133230  0.097724  0.002666\n",
       "question_expect_short_answer            0.703461    0.692459   0.011003  0.703461   0.692459  0.038672  0.667602\n",
       "question_fact_seeking                   0.804253    0.783605   0.020648  0.804253   0.783605  0.082285  0.018154\n",
       "question_has_commonly_accepted_answer   0.798511    0.741867   0.056644  0.798511   0.741867  0.120660  0.000084\n",
       "answer_type_instructions                0.521494    0.458585   0.062909  0.521494   0.458585  0.109700  0.000480\n",
       "question_type_instructions              0.560661    0.497071   0.063591  0.560661   0.497071  0.111697  0.000354"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_test_stats_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CULTURE</th>\n",
       "      <td>0.355161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIFE_ARTS</th>\n",
       "      <td>0.416903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SCIENCE</th>\n",
       "      <td>0.412144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STACKOVERFLOW</th>\n",
       "      <td>0.229831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TECHNOLOGY</th>\n",
       "      <td>0.362469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score\n",
       "CULTURE        0.355161\n",
       "LIFE_ARTS      0.416903\n",
       "SCIENCE        0.412144\n",
       "STACKOVERFLOW  0.229831\n",
       "TECHNOLOGY     0.362469"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_group_score  # this shows our current model performed bad on stackoverflow but great on life_art and science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>mae</th>\n",
       "      <th>mape</th>\n",
       "      <th>pearson</th>\n",
       "      <th>spearman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question_type_spelling</th>\n",
       "      <td>-0.000077</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>2.270338</td>\n",
       "      <td>0.037887</td>\n",
       "      <td>0.045481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.008318</td>\n",
       "      <td>1.896549</td>\n",
       "      <td>0.079877</td>\n",
       "      <td>0.056634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_plausible</th>\n",
       "      <td>-0.005538</td>\n",
       "      <td>0.063712</td>\n",
       "      <td>0.066673</td>\n",
       "      <td>0.099059</td>\n",
       "      <td>0.103282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_consequence</th>\n",
       "      <td>0.003327</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>1.601828</td>\n",
       "      <td>0.159365</td>\n",
       "      <td>0.148936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_relevance</th>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.050746</td>\n",
       "      <td>0.052423</td>\n",
       "      <td>0.167636</td>\n",
       "      <td>0.160318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_well_written</th>\n",
       "      <td>-0.012466</td>\n",
       "      <td>0.079821</td>\n",
       "      <td>0.087967</td>\n",
       "      <td>0.186088</td>\n",
       "      <td>0.183120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_helpful</th>\n",
       "      <td>-0.005366</td>\n",
       "      <td>0.088043</td>\n",
       "      <td>0.095494</td>\n",
       "      <td>0.228579</td>\n",
       "      <td>0.226554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <td>-0.002903</td>\n",
       "      <td>0.282184</td>\n",
       "      <td>0.409226</td>\n",
       "      <td>0.269054</td>\n",
       "      <td>0.262577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <td>-0.017276</td>\n",
       "      <td>0.161247</td>\n",
       "      <td>1.390612</td>\n",
       "      <td>0.262567</td>\n",
       "      <td>0.272878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.097911</td>\n",
       "      <td>0.114595</td>\n",
       "      <td>0.295653</td>\n",
       "      <td>0.279513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <td>-0.007475</td>\n",
       "      <td>0.102717</td>\n",
       "      <td>0.176640</td>\n",
       "      <td>0.324618</td>\n",
       "      <td>0.333692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_procedure</th>\n",
       "      <td>-0.007610</td>\n",
       "      <td>0.178714</td>\n",
       "      <td>1.198435</td>\n",
       "      <td>0.315674</td>\n",
       "      <td>0.334975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <td>-0.015787</td>\n",
       "      <td>0.223870</td>\n",
       "      <td>0.291566</td>\n",
       "      <td>0.456664</td>\n",
       "      <td>0.350735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <td>-0.018234</td>\n",
       "      <td>0.070575</td>\n",
       "      <td>0.107768</td>\n",
       "      <td>0.370518</td>\n",
       "      <td>0.363133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_compare</th>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.051535</td>\n",
       "      <td>1.135961</td>\n",
       "      <td>0.683542</td>\n",
       "      <td>0.376313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_definition</th>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.042347</td>\n",
       "      <td>1.069067</td>\n",
       "      <td>0.633965</td>\n",
       "      <td>0.380167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <td>-0.020978</td>\n",
       "      <td>0.090166</td>\n",
       "      <td>0.100928</td>\n",
       "      <td>0.338716</td>\n",
       "      <td>0.383365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <td>0.043084</td>\n",
       "      <td>0.237551</td>\n",
       "      <td>0.302631</td>\n",
       "      <td>0.497032</td>\n",
       "      <td>0.400842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_conversational</th>\n",
       "      <td>0.025276</td>\n",
       "      <td>0.073751</td>\n",
       "      <td>1.067630</td>\n",
       "      <td>0.556705</td>\n",
       "      <td>0.432150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <td>-0.018096</td>\n",
       "      <td>0.266724</td>\n",
       "      <td>0.619553</td>\n",
       "      <td>0.469810</td>\n",
       "      <td>0.448686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <td>-0.006046</td>\n",
       "      <td>0.127108</td>\n",
       "      <td>0.251095</td>\n",
       "      <td>0.469292</td>\n",
       "      <td>0.470368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_entity</th>\n",
       "      <td>-0.045226</td>\n",
       "      <td>0.098804</td>\n",
       "      <td>1.357576</td>\n",
       "      <td>0.649866</td>\n",
       "      <td>0.472563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_well_written</th>\n",
       "      <td>-0.021540</td>\n",
       "      <td>0.122321</td>\n",
       "      <td>0.152651</td>\n",
       "      <td>0.509772</td>\n",
       "      <td>0.513901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_multi_intent</th>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.216445</td>\n",
       "      <td>0.871033</td>\n",
       "      <td>0.542276</td>\n",
       "      <td>0.522495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <td>0.143093</td>\n",
       "      <td>0.264606</td>\n",
       "      <td>0.638204</td>\n",
       "      <td>0.577344</td>\n",
       "      <td>0.592825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_body_critical</th>\n",
       "      <td>-0.032300</td>\n",
       "      <td>0.144038</td>\n",
       "      <td>0.241994</td>\n",
       "      <td>0.611737</td>\n",
       "      <td>0.602926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <td>0.081127</td>\n",
       "      <td>0.265117</td>\n",
       "      <td>0.517329</td>\n",
       "      <td>0.640522</td>\n",
       "      <td>0.644250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_choice</th>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.181084</td>\n",
       "      <td>0.611095</td>\n",
       "      <td>0.698452</td>\n",
       "      <td>0.709525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <td>0.009891</td>\n",
       "      <td>0.210185</td>\n",
       "      <td>0.448658</td>\n",
       "      <td>0.773626</td>\n",
       "      <td>0.759968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_instructions</th>\n",
       "      <td>-0.020646</td>\n",
       "      <td>0.201364</td>\n",
       "      <td>0.422655</td>\n",
       "      <td>0.787547</td>\n",
       "      <td>0.760115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           bias       mae      mape   pearson  spearman\n",
       "question_type_spelling                -0.000077  0.000622  2.270338  0.037887  0.045481\n",
       "question_not_really_a_question         0.000245  0.008318  1.896549  0.079877  0.056634\n",
       "answer_plausible                      -0.005538  0.063712  0.066673  0.099059  0.103282\n",
       "question_type_consequence              0.003327  0.016466  1.601828  0.159365  0.148936\n",
       "answer_relevance                       0.002329  0.050746  0.052423  0.167636  0.160318\n",
       "answer_well_written                   -0.012466  0.079821  0.087967  0.186088  0.183120\n",
       "answer_helpful                        -0.005366  0.088043  0.095494  0.228579  0.226554\n",
       "question_expect_short_answer          -0.002903  0.282184  0.409226  0.269054  0.262577\n",
       "answer_type_procedure                 -0.017276  0.161247  1.390612  0.262567  0.272878\n",
       "answer_satisfaction                    0.008916  0.097911  0.114595  0.295653  0.279513\n",
       "question_interestingness_others       -0.007475  0.102717  0.176640  0.324618  0.333692\n",
       "question_type_procedure               -0.007610  0.178714  1.198435  0.315674  0.334975\n",
       "question_fact_seeking                 -0.015787  0.223870  0.291566  0.456664  0.350735\n",
       "answer_level_of_information           -0.018234  0.070575  0.107768  0.370518  0.363133\n",
       "question_type_compare                  0.001250  0.051535  1.135961  0.683542  0.376313\n",
       "question_type_definition               0.000143  0.042347  1.069067  0.633965  0.380167\n",
       "question_asker_intent_understanding   -0.020978  0.090166  0.100928  0.338716  0.383365\n",
       "question_has_commonly_accepted_answer  0.043084  0.237551  0.302631  0.497032  0.400842\n",
       "question_conversational                0.025276  0.073751  1.067630  0.556705  0.432150\n",
       "question_opinion_seeking              -0.018096  0.266724  0.619553  0.469810  0.448686\n",
       "question_interestingness_self         -0.006046  0.127108  0.251095  0.469292  0.470368\n",
       "question_type_entity                  -0.045226  0.098804  1.357576  0.649866  0.472563\n",
       "question_well_written                 -0.021540  0.122321  0.152651  0.509772  0.513901\n",
       "question_multi_intent                  0.004440  0.216445  0.871033  0.542276  0.522495\n",
       "question_type_reason_explanation       0.143093  0.264606  0.638204  0.577344  0.592825\n",
       "question_body_critical                -0.032300  0.144038  0.241994  0.611737  0.602926\n",
       "answer_type_reason_explanation         0.081127  0.265117  0.517329  0.640522  0.644250\n",
       "question_type_choice                   0.035714  0.181084  0.611095  0.698452  0.709525\n",
       "answer_type_instructions               0.009891  0.210185  0.448658  0.773626  0.759968\n",
       "question_type_instructions            -0.020646  0.201364  0.422655  0.787547  0.760115"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_breakdown_metrics  # pre-sorted the model performance by spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_asker_intent_understanding  question_body_critical  question_conversational  question_expect_short_answer  question_fact_seeking  question_has_commonly_accepted_answer  question_interestingness_others  question_interestingness_self  question_multi_intent  question_not_really_a_question  question_opinion_seeking  question_type_choice  question_type_compare  question_type_consequence  question_type_definition  question_type_entity  question_type_instructions  question_type_procedure  question_type_reason_explanation  question_type_spelling  question_well_written  answer_helpful  answer_level_of_information  answer_plausible  answer_relevance  answer_satisfaction  answer_type_instructions  answer_type_procedure  answer_type_reason_explanation  answer_well_written\n",
       "qa_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "6                                 1.000000                0.666667                      0.0                      0.500000               1.000000                               1.000000                         0.444444                       0.333333                    0.0                             0.0                  0.500000              0.000000               0.000000                        0.0                  0.000000              0.000000                    1.000000                      0.5                          0.000000                     0.0               0.833333        0.888889                     0.666667          0.888889          1.000000             0.733333                  0.666667               0.666667                        0.000000             0.777778\n",
       "11                                1.000000                0.333333                      0.0                      1.000000               1.000000                               1.000000                         0.666667                       0.555556                    0.0                             0.0                  0.333333              0.333333               0.000000                        0.0                  0.000000              0.000000                    0.666667                      0.0                          0.333333                     0.0               0.888889        0.666667                     0.333333          0.666667          0.666667             0.266667                  0.000000               0.000000                        0.000000             0.888889\n",
       "17                                0.888889                1.000000                      0.0                      0.000000               1.000000                               0.000000                         0.666667                       0.333333                    0.0                             0.0                  0.000000              0.000000               0.333333                        0.0                  0.000000              0.000000                    0.000000                      0.0                          0.666667                     0.0               1.000000        1.000000                     0.666667          1.000000          1.000000             1.000000                  0.000000               0.000000                        1.000000             1.000000\n",
       "24                                0.777778                0.555556                      0.0                      1.000000               0.666667                               1.000000                         0.555556                       0.333333                    0.0                             0.0                  0.333333              1.000000               0.000000                        0.0                  0.000000              0.000000                    0.666667                      0.0                          0.666667                     0.0               0.888889        0.666667                     0.666667          0.666667          0.888889             0.900000                  0.333333               0.333333                        0.666667             1.000000\n",
       "41                                0.888889                0.666667                      0.0                      0.333333               1.000000                               0.666667                         0.555556                       0.444444                    1.0                             0.0                  0.000000              0.333333               0.000000                        0.0                  0.333333              0.333333                    0.000000                      0.0                          0.666667                     0.0               1.000000        0.888889                     0.555556          1.000000          1.000000             0.800000                  0.000000               0.000000                        0.333333             1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_trues.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <th>question_type_choice</th>\n",
       "      <th>question_type_compare</th>\n",
       "      <th>question_type_consequence</th>\n",
       "      <th>question_type_definition</th>\n",
       "      <th>question_type_entity</th>\n",
       "      <th>question_type_instructions</th>\n",
       "      <th>question_type_procedure</th>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <th>question_type_spelling</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.913903</td>\n",
       "      <td>0.574332</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>0.683393</td>\n",
       "      <td>0.753354</td>\n",
       "      <td>0.738192</td>\n",
       "      <td>0.556214</td>\n",
       "      <td>0.423216</td>\n",
       "      <td>0.066570</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.551079</td>\n",
       "      <td>0.051694</td>\n",
       "      <td>0.004357</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.082212</td>\n",
       "      <td>0.881789</td>\n",
       "      <td>0.266576</td>\n",
       "      <td>0.042201</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.779110</td>\n",
       "      <td>0.917146</td>\n",
       "      <td>0.620512</td>\n",
       "      <td>0.963767</td>\n",
       "      <td>0.968732</td>\n",
       "      <td>0.816445</td>\n",
       "      <td>0.822706</td>\n",
       "      <td>0.133666</td>\n",
       "      <td>0.055822</td>\n",
       "      <td>0.911258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.860276</td>\n",
       "      <td>0.545545</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.755446</td>\n",
       "      <td>0.882033</td>\n",
       "      <td>0.882884</td>\n",
       "      <td>0.557784</td>\n",
       "      <td>0.447238</td>\n",
       "      <td>0.315605</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.280138</td>\n",
       "      <td>0.387065</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>0.016210</td>\n",
       "      <td>0.025293</td>\n",
       "      <td>0.189753</td>\n",
       "      <td>0.262477</td>\n",
       "      <td>0.110225</td>\n",
       "      <td>0.459036</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.721503</td>\n",
       "      <td>0.865184</td>\n",
       "      <td>0.656405</td>\n",
       "      <td>0.919287</td>\n",
       "      <td>0.937834</td>\n",
       "      <td>0.749343</td>\n",
       "      <td>0.201835</td>\n",
       "      <td>0.124105</td>\n",
       "      <td>0.445069</td>\n",
       "      <td>0.852494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.930392</td>\n",
       "      <td>0.746779</td>\n",
       "      <td>0.006125</td>\n",
       "      <td>0.309692</td>\n",
       "      <td>0.962183</td>\n",
       "      <td>0.885127</td>\n",
       "      <td>0.673433</td>\n",
       "      <td>0.552903</td>\n",
       "      <td>0.618383</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.085606</td>\n",
       "      <td>0.028880</td>\n",
       "      <td>0.271529</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.075362</td>\n",
       "      <td>0.030754</td>\n",
       "      <td>0.114819</td>\n",
       "      <td>0.108604</td>\n",
       "      <td>0.775594</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.850926</td>\n",
       "      <td>0.947082</td>\n",
       "      <td>0.720570</td>\n",
       "      <td>0.979831</td>\n",
       "      <td>0.983407</td>\n",
       "      <td>0.914241</td>\n",
       "      <td>0.077692</td>\n",
       "      <td>0.136435</td>\n",
       "      <td>0.886666</td>\n",
       "      <td>0.932496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.904079</td>\n",
       "      <td>0.513168</td>\n",
       "      <td>0.005836</td>\n",
       "      <td>0.790587</td>\n",
       "      <td>0.851329</td>\n",
       "      <td>0.865632</td>\n",
       "      <td>0.586556</td>\n",
       "      <td>0.417086</td>\n",
       "      <td>0.330288</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.504178</td>\n",
       "      <td>0.819299</td>\n",
       "      <td>0.040932</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>0.001140</td>\n",
       "      <td>0.040498</td>\n",
       "      <td>0.439039</td>\n",
       "      <td>0.112704</td>\n",
       "      <td>0.158191</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.799131</td>\n",
       "      <td>0.978650</td>\n",
       "      <td>0.744484</td>\n",
       "      <td>0.989262</td>\n",
       "      <td>0.989302</td>\n",
       "      <td>0.913242</td>\n",
       "      <td>0.346648</td>\n",
       "      <td>0.146935</td>\n",
       "      <td>0.721115</td>\n",
       "      <td>0.950358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.894373</td>\n",
       "      <td>0.590808</td>\n",
       "      <td>0.052658</td>\n",
       "      <td>0.454970</td>\n",
       "      <td>0.898931</td>\n",
       "      <td>0.671971</td>\n",
       "      <td>0.612816</td>\n",
       "      <td>0.574072</td>\n",
       "      <td>0.730754</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.317559</td>\n",
       "      <td>0.279242</td>\n",
       "      <td>0.319637</td>\n",
       "      <td>0.025260</td>\n",
       "      <td>0.123637</td>\n",
       "      <td>0.055559</td>\n",
       "      <td>0.189252</td>\n",
       "      <td>0.154059</td>\n",
       "      <td>0.415576</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.831692</td>\n",
       "      <td>0.868908</td>\n",
       "      <td>0.623571</td>\n",
       "      <td>0.940311</td>\n",
       "      <td>0.931832</td>\n",
       "      <td>0.798913</td>\n",
       "      <td>0.102962</td>\n",
       "      <td>0.127883</td>\n",
       "      <td>0.636078</td>\n",
       "      <td>0.890738</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       question_asker_intent_understanding  question_body_critical  question_conversational  question_expect_short_answer  question_fact_seeking  question_has_commonly_accepted_answer  question_interestingness_others  question_interestingness_self  question_multi_intent  question_not_really_a_question  question_opinion_seeking  question_type_choice  question_type_compare  question_type_consequence  question_type_definition  question_type_entity  question_type_instructions  question_type_procedure  question_type_reason_explanation  question_type_spelling  question_well_written  answer_helpful  answer_level_of_information  answer_plausible  answer_relevance  answer_satisfaction  answer_type_instructions  answer_type_procedure  answer_type_reason_explanation  answer_well_written\n",
       "qa_id                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "6                                 0.913903                0.574332                 0.008799                      0.683393               0.753354                               0.738192                         0.556214                       0.423216               0.066570                        0.002666                  0.551079              0.051694               0.004357                   0.000341                  0.000446              0.082212                    0.881789                 0.266576                          0.042201                0.000005               0.779110        0.917146                     0.620512          0.963767          0.968732             0.816445                  0.822706               0.133666                        0.055822             0.911258\n",
       "11                                0.860276                0.545545                 0.009622                      0.755446               0.882033                               0.882884                         0.557784                       0.447238               0.315605                        0.004348                  0.280138              0.387065               0.020527                   0.016210                  0.025293              0.189753                    0.262477                 0.110225                          0.459036                0.002040               0.721503        0.865184                     0.656405          0.919287          0.937834             0.749343                  0.201835               0.124105                        0.445069             0.852494\n",
       "17                                0.930392                0.746779                 0.006125                      0.309692               0.962183                               0.885127                         0.673433                       0.552903               0.618383                        0.000332                  0.085606              0.028880               0.271529                   0.009798                  0.075362              0.030754                    0.114819                 0.108604                          0.775594                0.000071               0.850926        0.947082                     0.720570          0.979831          0.983407             0.914241                  0.077692               0.136435                        0.886666             0.932496\n",
       "24                                0.904079                0.513168                 0.005836                      0.790587               0.851329                               0.865632                         0.586556                       0.417086               0.330288                        0.000520                  0.504178              0.819299               0.040932                   0.005569                  0.001140              0.040498                    0.439039                 0.112704                          0.158191                0.000021               0.799131        0.978650                     0.744484          0.989262          0.989302             0.913242                  0.346648               0.146935                        0.721115             0.950358\n",
       "41                                0.894373                0.590808                 0.052658                      0.454970               0.898931                               0.671971                         0.612816                       0.574072               0.730754                        0.003479                  0.317559              0.279242               0.319637                   0.025260                  0.123637              0.055559                    0.189252                 0.154059                          0.415576                0.002474               0.831692        0.868908                     0.623571          0.940311          0.931832             0.798913                  0.102962               0.127883                        0.636078             0.890738"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lift from post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../nlp_utils\")\n",
    "\n",
    "from nlp_utils import OptimalRounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting: question_asker_intent_understanding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in greater\n",
      "  return (a < x) & (x < b)\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:903: RuntimeWarning: invalid value encountered in less\n",
      "  return (a < x) & (x < b)\n",
      "/usr/local/lib/python3.6/dist-packages/scipy/stats/_distn_infrastructure.py:1912: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= _a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting: question_body_critical\n",
      "fitting: question_conversational\n",
      "fitting: question_expect_short_answer\n",
      "fitting: question_fact_seeking\n",
      "fitting: question_has_commonly_accepted_answer\n",
      "fitting: question_interestingness_others\n",
      "fitting: question_interestingness_self\n",
      "fitting: question_multi_intent\n",
      "fitting: question_not_really_a_question\n",
      "fitting: question_opinion_seeking\n",
      "fitting: question_type_choice\n",
      "fitting: question_type_compare\n",
      "fitting: question_type_consequence\n",
      "fitting: question_type_definition\n",
      "fitting: question_type_entity\n",
      "fitting: question_type_instructions\n",
      "fitting: question_type_procedure\n",
      "fitting: question_type_reason_explanation\n",
      "fitting: question_type_spelling\n",
      "fitting: question_well_written\n",
      "fitting: answer_helpful\n",
      "fitting: answer_level_of_information\n",
      "fitting: answer_plausible\n",
      "fitting: answer_relevance\n",
      "fitting: answer_satisfaction\n",
      "fitting: answer_type_instructions\n",
      "fitting: answer_type_procedure\n",
      "fitting: answer_type_reason_explanation\n",
      "fitting: answer_well_written\n"
     ]
    }
   ],
   "source": [
    "# training optimal rounder from the indices distribution from training\n",
    "\n",
    "df = pd.read_csv('../input/google-quest-challenge/train.csv')[valid_preds.columns]\n",
    "opt = OptimalRounder(ref=df)\n",
    "valid_preds_opt = opt.fit_transform(valid_trues, valid_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Optimal Rounder using random search to find best threshold discretize the continous outputs from our model. Discretized the model outputs as post-processing is the key process to lift model and maximize the model perform. Is is also written in fast and effecitve pythonic  way with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_asker_intent_understanding      0.383365\n",
       "question_body_critical                   0.602926\n",
       "question_conversational                  0.432150\n",
       "question_expect_short_answer             0.262577\n",
       "question_fact_seeking                    0.350735\n",
       "question_has_commonly_accepted_answer    0.400842\n",
       "question_interestingness_others          0.333692\n",
       "question_interestingness_self            0.470368\n",
       "question_multi_intent                    0.522495\n",
       "question_not_really_a_question           0.056634\n",
       "question_opinion_seeking                 0.448686\n",
       "question_type_choice                     0.709525\n",
       "question_type_compare                    0.376313\n",
       "question_type_consequence                0.148936\n",
       "question_type_definition                 0.380167\n",
       "question_type_entity                     0.472563\n",
       "question_type_instructions               0.760115\n",
       "question_type_procedure                  0.334975\n",
       "question_type_reason_explanation         0.592825\n",
       "question_type_spelling                   0.045481\n",
       "question_well_written                    0.513901\n",
       "answer_helpful                           0.226554\n",
       "answer_level_of_information              0.363133\n",
       "answer_plausible                         0.103282\n",
       "answer_relevance                         0.160318\n",
       "answer_satisfaction                      0.279513\n",
       "answer_type_instructions                 0.759968\n",
       "answer_type_procedure                    0.272878\n",
       "answer_type_reason_explanation           0.644250\n",
       "answer_well_written                      0.183120\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_scores_orig = valid_trues.apply(lambda x: x.corr(valid_preds[x.name], method='spearman'))\n",
    "valid_scores_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_asker_intent_understanding      0.377789\n",
       "question_body_critical                   0.603422\n",
       "question_conversational                  0.535739\n",
       "question_expect_short_answer             0.282926\n",
       "question_fact_seeking                    0.369103\n",
       "question_has_commonly_accepted_answer    0.432656\n",
       "question_interestingness_others          0.344361\n",
       "question_interestingness_self            0.484238\n",
       "question_multi_intent                    0.522911\n",
       "question_not_really_a_question                NaN\n",
       "question_opinion_seeking                 0.454448\n",
       "question_type_choice                     0.721485\n",
       "question_type_compare                    0.580100\n",
       "question_type_consequence                     NaN\n",
       "question_type_definition                 0.604581\n",
       "question_type_entity                     0.612240\n",
       "question_type_instructions               0.781821\n",
       "question_type_procedure                  0.342245\n",
       "question_type_reason_explanation         0.592867\n",
       "question_type_spelling                        NaN\n",
       "question_well_written                    0.515175\n",
       "answer_helpful                           0.227726\n",
       "answer_level_of_information              0.368822\n",
       "answer_plausible                         0.105992\n",
       "answer_relevance                         0.168691\n",
       "answer_satisfaction                      0.291571\n",
       "answer_type_instructions                 0.766692\n",
       "answer_type_procedure                    0.293014\n",
       "answer_type_reason_explanation           0.640327\n",
       "answer_well_written                      0.181856\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score after post processing on validation set\n",
    "valid_scores_opt = valid_trues.apply(lambda x: x.corr(valid_preds_opt[x.name], method='spearman'))\n",
    "valid_scores_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_asker_intent_understanding      5\n",
       "question_body_critical                   8\n",
       "question_conversational                  3\n",
       "question_expect_short_answer             5\n",
       "question_fact_seeking                    5\n",
       "question_has_commonly_accepted_answer    5\n",
       "question_interestingness_others          7\n",
       "question_interestingness_self            6\n",
       "question_multi_intent                    5\n",
       "question_not_really_a_question           1\n",
       "question_opinion_seeking                 5\n",
       "question_type_choice                     5\n",
       "question_type_compare                    5\n",
       "question_type_consequence                1\n",
       "question_type_definition                 4\n",
       "question_type_entity                     5\n",
       "question_type_instructions               5\n",
       "question_type_procedure                  3\n",
       "question_type_reason_explanation         5\n",
       "question_type_spelling                   1\n",
       "question_well_written                    7\n",
       "answer_helpful                           3\n",
       "answer_level_of_information              6\n",
       "answer_plausible                         4\n",
       "answer_relevance                         4\n",
       "answer_satisfaction                      8\n",
       "answer_type_instructions                 5\n",
       "answer_type_procedure                    5\n",
       "answer_type_reason_explanation           5\n",
       "answer_well_written                      4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_preds_opt.apply(lambda x: x.nunique())  \n",
    "# check the unique value counts in every index after post processing, only one unique value make scoring become NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "question_type_definition                 0.224414\n",
       "question_type_compare                    0.203787\n",
       "question_type_entity                     0.139677\n",
       "question_conversational                  0.103589\n",
       "question_has_commonly_accepted_answer    0.031814\n",
       "question_type_instructions               0.021706\n",
       "question_expect_short_answer             0.020349\n",
       "answer_type_procedure                    0.020136\n",
       "question_fact_seeking                    0.018368\n",
       "question_interestingness_self            0.013870\n",
       "answer_satisfaction                      0.012058\n",
       "question_type_choice                     0.011960\n",
       "question_interestingness_others          0.010669\n",
       "answer_relevance                         0.008373\n",
       "question_type_procedure                  0.007271\n",
       "answer_type_instructions                 0.006723\n",
       "question_opinion_seeking                 0.005762\n",
       "answer_level_of_information              0.005688\n",
       "answer_plausible                         0.002710\n",
       "question_well_written                    0.001274\n",
       "answer_helpful                           0.001172\n",
       "question_body_critical                   0.000496\n",
       "question_multi_intent                    0.000416\n",
       "question_type_reason_explanation         0.000043\n",
       "answer_well_written                     -0.001264\n",
       "answer_type_reason_explanation          -0.003924\n",
       "question_asker_intent_understanding     -0.005576\n",
       "question_not_really_a_question                NaN\n",
       "question_type_consequence                     NaN\n",
       "question_type_spelling                        NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eyeballing the improvement on every attribute\n",
    "valid_scores_opt_diff = (valid_scores_opt - valid_scores_orig).sort_values(ascending=False)\n",
    "valid_scores_opt_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select 24 labels getting improve: ['question_type_definition', 'question_type_compare', 'question_type_entity', 'question_conversational', 'question_has_commonly_accepted_answer', 'question_type_instructions', 'question_expect_short_answer', 'answer_type_procedure', 'question_fact_seeking', 'question_interestingness_self', 'answer_satisfaction', 'question_type_choice', 'question_interestingness_others', 'answer_relevance', 'question_type_procedure', 'answer_type_instructions', 'question_opinion_seeking', 'answer_level_of_information', 'answer_plausible', 'question_well_written', 'answer_helpful', 'question_body_critical', 'question_multi_intent', 'question_type_reason_explanation']\n"
     ]
    }
   ],
   "source": [
    "# apply useful columns only, has improvement, and not NaN in metrics\n",
    "use_cols = valid_scores_opt_diff.loc[valid_scores_opt_diff > -.0010].dropna().index.tolist()\n",
    "print(f\"select {len(use_cols)} labels getting improve: {use_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig score=0.386, optimized score=0.415, improve=0.029\n"
     ]
    }
   ],
   "source": [
    "# calculate the lift from post processing\n",
    "valid_preds_opt_final = valid_preds.copy()\n",
    "valid_preds_opt_final[use_cols] = opt.transform(valid_preds[use_cols])\n",
    "\n",
    "score_orig = spearmanr_ignore_nan(valid_trues.values, valid_preds.values)\n",
    "score_opt = spearmanr_ignore_nan(valid_trues.values, valid_preds_opt_final.values)\n",
    "\n",
    "print(f\"orig score={score_orig:.3f}, optimized score={score_opt:.3f}, improve={score_opt-score_orig:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>qa_id</th>\n",
       "      <th>39</th>\n",
       "      <th>46</th>\n",
       "      <th>70</th>\n",
       "      <th>132</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <td>0.947959</td>\n",
       "      <td>0.884822</td>\n",
       "      <td>0.932607</td>\n",
       "      <td>0.875872</td>\n",
       "      <td>0.937934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_body_critical</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_conversational</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_multi_intent</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_not_really_a_question</th>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.009392</td>\n",
       "      <td>0.001906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_opinion_seeking</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_choice</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_compare</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_consequence</th>\n",
       "      <td>0.074635</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.038984</td>\n",
       "      <td>0.002499</td>\n",
       "      <td>0.007578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_definition</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_entity</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_instructions</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_procedure</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_reason_explanation</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_type_spelling</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question_well_written</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_helpful</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_plausible</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_relevance</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <td>0.535235</td>\n",
       "      <td>0.122213</td>\n",
       "      <td>0.573408</td>\n",
       "      <td>0.566220</td>\n",
       "      <td>0.591768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>answer_well_written</th>\n",
       "      <td>0.920486</td>\n",
       "      <td>0.899980</td>\n",
       "      <td>0.901861</td>\n",
       "      <td>0.901522</td>\n",
       "      <td>0.931824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "qa_id                                       39        46        70        132       200\n",
       "question_asker_intent_understanding    0.947959  0.884822  0.932607  0.875872  0.937934\n",
       "question_body_critical                 0.833333  0.555556  0.888889  0.500000  0.666667\n",
       "question_conversational                0.333333  0.000000  0.000000  0.000000  0.000000\n",
       "question_expect_short_answer           0.333333  0.666667  0.666667  0.500000  0.666667\n",
       "question_fact_seeking                  0.333333  0.666667  0.666667  0.666667  0.666667\n",
       "question_has_commonly_accepted_answer  0.333333  1.000000  1.000000  1.000000  1.000000\n",
       "question_interestingness_others        0.888889  0.500000  0.666667  0.500000  0.555556\n",
       "question_interestingness_self          0.666667  0.500000  0.500000  0.500000  0.555556\n",
       "question_multi_intent                  0.666667  0.000000  0.000000  0.000000  0.666667\n",
       "question_not_really_a_question         0.001387  0.002109  0.001294  0.009392  0.001906\n",
       "question_opinion_seeking               1.000000  0.333333  0.333333  0.500000  0.000000\n",
       "question_type_choice                   0.666667  0.666667  1.000000  0.000000  1.000000\n",
       "question_type_compare                  0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "question_type_consequence              0.074635  0.000464  0.038984  0.002499  0.007578\n",
       "question_type_definition               0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "question_type_entity                   0.000000  0.000000  0.000000  0.000000  0.000000\n",
       "question_type_instructions             0.000000  1.000000  0.333333  1.000000  0.500000\n",
       "question_type_procedure                0.000000  0.333333  0.000000  0.333333  0.333333\n",
       "question_type_reason_explanation       0.666667  0.000000  0.500000  0.666667  0.333333\n",
       "question_type_spelling                 0.000076  0.000007  0.000241  0.000036  0.000497\n",
       "question_well_written                  1.000000  0.666667  0.888889  0.666667  0.833333\n",
       "answer_helpful                         0.833333  1.000000  0.888889  0.888889  1.000000\n",
       "answer_level_of_information            0.666667  0.833333  0.666667  0.833333  0.833333\n",
       "answer_plausible                       0.888889  1.000000  0.888889  1.000000  1.000000\n",
       "answer_relevance                       0.777778  1.000000  0.833333  1.000000  0.888889\n",
       "answer_satisfaction                    0.733333  0.866667  0.866667  0.866667  0.933333\n",
       "answer_type_instructions               0.000000  1.000000  0.333333  1.000000  0.500000\n",
       "answer_type_procedure                  0.333333  0.500000  0.333333  0.500000  0.500000\n",
       "answer_type_reason_explanation         0.535235  0.122213  0.573408  0.566220  0.591768\n",
       "answer_well_written                    0.920486  0.899980  0.901861  0.901522  0.931824"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# successfully apply the same post processing to test prediction\n",
    "test_preds[use_cols] = opt.transform(test_preds[use_cols])\n",
    "test_preds.head().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
